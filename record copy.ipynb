{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import os,cv2\n",
    "import argparse\n",
    "\n",
    "from tracker.ucmc import UCMCTrack\n",
    "from detector.mapper import Mapper\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# 定义一个Detection类，包含id,bb_left,bb_top,bb_width,bb_height,conf,det_class\n",
    "class Detection:\n",
    "\n",
    "    def __init__(self, id, bb_left = 0, bb_top = 0, bb_width = 0, bb_height = 0, conf = 0, det_class = 0):\n",
    "        self.id = id\n",
    "        self.bb_left = bb_left\n",
    "        self.bb_top = bb_top\n",
    "        self.bb_width = bb_width\n",
    "        self.bb_height = bb_height\n",
    "        self.conf = conf\n",
    "        self.det_class = det_class\n",
    "        self.track_id = 0\n",
    "        self.y = np.zeros((2, 1))\n",
    "        self.R = np.eye(4)\n",
    "\n",
    "\n",
    "    def __str__(self):\n",
    "        return 'd{}, bb_box:[{},{},{},{}], conf={:.2f}, class{}, uv:[{:.0f},{:.0f}], mapped to:[{:.1f},{:.1f}]'.format(\n",
    "            self.id, self.bb_left, self.bb_top, self.bb_width, self.bb_height, self.conf, self.det_class,\n",
    "            self.bb_left+self.bb_width/2,self.bb_top+self.bb_height,self.y[0,0],self.y[1,0])\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__str__()\n",
    "\n",
    "\n",
    "# Detector类，用于从Yolo检测器获取目标检测的结果\n",
    "class Detector:\n",
    "    def __init__(self):\n",
    "        self.seq_length = 0\n",
    "        self.gmc = None\n",
    "\n",
    "    def load(self,cam_para_file):\n",
    "        self.mapper = Mapper(cam_para_file,\"MOT17\")\n",
    "        self.model = YOLO('pretrained/yolov8x.pt')\n",
    "\n",
    "    def get_dets(self, img,conf_thresh = 0,det_classes = [0]):\n",
    "        \n",
    "        dets = []\n",
    "\n",
    "        # 将帧从 BGR 转换为 RGB（因为 OpenCV 使用 BGR 格式）  \n",
    "        frame = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  \n",
    "\n",
    "        # 使用 RTDETR 进行推理  \n",
    "        results = self.model(frame,imgsz = 1088)\n",
    "\n",
    "        det_id = 0\n",
    "        for box in results[0].boxes:\n",
    "            conf = box.conf.cpu().numpy()[0]\n",
    "            bbox = box.xyxy.cpu().numpy()[0]\n",
    "            cls_id  = box.cls.cpu().numpy()[0]\n",
    "            w = bbox[2] - bbox[0]\n",
    "            h = bbox[3] - bbox[1]\n",
    "            if w <= 10 and h <= 10 or cls_id not in det_classes or conf <= conf_thresh:\n",
    "                continue\n",
    "\n",
    "            # 新建一个Detection对象\n",
    "            det = Detection(det_id)\n",
    "            det.bb_left = bbox[0]\n",
    "            det.bb_top = bbox[1]\n",
    "            det.bb_width = w\n",
    "            det.bb_height = h\n",
    "            det.conf = conf\n",
    "            det.det_class = cls_id\n",
    "            det.y,det.R = self.mapper.mapto([det.bb_left,det.bb_top,det.bb_width,det.bb_height])\n",
    "            det_id += 1\n",
    "\n",
    "            dets.append(det)\n",
    "\n",
    "        return dets\n",
    "    \n",
    "\n",
    "def main(args):\n",
    "\n",
    "    class_list = [2,5,7]\n",
    "\n",
    "    cap = cv2.VideoCapture(args.video)\n",
    "\n",
    "    # 获取视频的 fps\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "    # 获取视频的宽度和高度\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    video_out = cv2.VideoWriter('output/output.mp4', cv2.VideoWriter_fourcc(*'mp4v'), fps, (width, height))  \n",
    "\n",
    "    # 打开一个cv的窗口，指定高度和宽度\n",
    "    cv2.namedWindow(\"demo\", cv2.WINDOW_NORMAL)\n",
    "    cv2.resizeWindow(\"demo\", width, height)\n",
    "\n",
    "    detector = Detector()\n",
    "    detector.load(args.cam_para)\n",
    "\n",
    "    \n",
    "    tracker = UCMCTrack(args.a, args.a, args.wx, args.wy, args.vmax, args.cdt, fps, \"MOT\", args.high_score,False,None)\n",
    "\n",
    "    # 循环读取视频帧\n",
    "    frame_id = 1\n",
    "    while True:\n",
    "        ret, frame_img = cap.read()\n",
    "        if not ret:  \n",
    "            break\n",
    "    \n",
    "        dets = detector.get_dets(frame_img,args.conf_thresh,class_list)\n",
    "        tracker.update(dets,frame_id)\n",
    "\n",
    "        for det in dets:\n",
    "            # 画出检测框\n",
    "            if det.track_id > 0:\n",
    "                cv2.rectangle(frame_img, (int(det.bb_left), int(det.bb_top)), (int(det.bb_left+det.bb_width), int(det.bb_top+det.bb_height)), (0, 255, 0), 2)\n",
    "                # 画出检测框的id\n",
    "                cv2.putText(frame_img, str(det.track_id), (int(det.bb_left), int(det.bb_top)), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "\n",
    "        frame_id += 1\n",
    "\n",
    "\n",
    "        # 显示当前帧\n",
    "        cv2.imshow(\"demo\", frame_img)\n",
    "        cv2.waitKey(1)\n",
    "\n",
    "        video_out.write(frame_img)\n",
    "    \n",
    "    cap.release()\n",
    "    video_out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Process some arguments.')\n",
    "parser.add_argument('--video', type=str, default = \"demo/demo.mp4\", help='video file name')\n",
    "parser.add_argument('--cam_para', type=str, default = \"demo/cam_para.txt\", help='camera parameter file name')\n",
    "parser.add_argument('--wx', type=float, default=5, help='wx')\n",
    "parser.add_argument('--wy', type=float, default=5, help='wy')\n",
    "parser.add_argument('--vmax', type=float, default=10, help='vmax')\n",
    "parser.add_argument('--a', type=float, default=100.0, help='assignment threshold')\n",
    "parser.add_argument('--cdt', type=float, default=10.0, help='coasted deletion time')\n",
    "parser.add_argument('--high_score', type=float, default=0.5, help='high score threshold')\n",
    "parser.add_argument('--conf_thresh', type=float, default=0.01, help='detection confidence threshold')\n",
    "args = parser.parse_args()\n",
    "\n",
    "main(args)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# working plot without canvas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import json\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from ultralytics import YOLO\n",
    "from tracker.ucmc import UCMCTrack\n",
    "from detector.mapper import Mapper\n",
    "from collections import defaultdict\n",
    "import argparse\n",
    "\n",
    "# 定义一个Detection类\n",
    "class Detection:\n",
    "    def __init__(self, id, bb_left=0, bb_top=0, bb_width=0, bb_height=0, conf=0, det_class=0):\n",
    "        self.id = id\n",
    "        self.bb_left = bb_left\n",
    "        self.bb_top = bb_top\n",
    "        self.bb_width = bb_width\n",
    "        self.bb_height = bb_height\n",
    "        self.conf = conf\n",
    "        self.det_class = det_class\n",
    "        self.track_id = 0\n",
    "        self.y = np.zeros((2, 1))\n",
    "        self.R = np.eye(4)\n",
    "\n",
    "    def __str__(self):\n",
    "        return f'd{self.id}, bb_box:[{self.bb_left},{self.bb_top},{self.bb_width},{self.bb_height}], conf={self.conf:.2f}, class{self.det_class}, uv:[{self.bb_left+self.bb_width/2},{self.bb_top+self.bb_height}], mapped to:[{self.y[0,0]},{self.y[1,0]}]'\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__str__()\n",
    "\n",
    "# Detector类\n",
    "class Detector:\n",
    "    def __init__(self):\n",
    "        self.seq_length = 0\n",
    "        self.gmc = None\n",
    "\n",
    "    def load(self, cam_para_file, yolo_version):\n",
    "        self.mapper = Mapper(cam_para_file, \"MOT17\")\n",
    "        self.model = YOLO(f'pretrained/{yolo_version}.pt')\n",
    "\n",
    "    def get_dets(self, img, conf_thresh=0, det_classes=[0]):\n",
    "        dets = []\n",
    "        frame = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        results = self.model(frame, imgsz=1088)\n",
    "        det_id = 0\n",
    "        for box in results[0].boxes:\n",
    "            conf = box.conf.cpu().numpy()[0]\n",
    "            bbox = box.xyxy.cpu().numpy()[0]\n",
    "            cls_id = box.cls.cpu().numpy()[0]\n",
    "            w = bbox[2] - bbox[0]\n",
    "            h = bbox[3] - bbox[1]\n",
    "            if w <= 10 and h <= 10 or cls_id not in det_classes or conf <= conf_thresh:\n",
    "                continue\n",
    "\n",
    "            det = Detection(det_id)\n",
    "            det.bb_left = bbox[0]\n",
    "            det.bb_top = bbox[1]\n",
    "            det.bb_width = w\n",
    "            det.bb_height = h\n",
    "            det.conf = conf\n",
    "            det.det_class = cls_id\n",
    "            det.y, det.R = self.mapper.mapto([det.bb_left, det.bb_top, det.bb_width, det.bb_height])\n",
    "            det_id += 1\n",
    "            dets.append(det)\n",
    "\n",
    "        return dets\n",
    "\n",
    "# Function to apply the ROI mask with green overlay\n",
    "def apply_green_roi_mask(frame, points):\n",
    "    overlay = frame.copy()\n",
    "    cv2.fillPoly(overlay, [points], (0, 255, 0))  # Green color\n",
    "    alpha = 0.3  # Transparency\n",
    "    cv2.addWeighted(overlay, alpha, frame, 1 - alpha, 0, frame)\n",
    "    return frame\n",
    "\n",
    "# Set up ROI points\n",
    "roi_points = np.array([\n",
    "    [28, 1046], [109, 977], [269, 846], [426, 715], [507, 614],\n",
    "    [570, 520], [521, 456], [427, 411], [308, 392], [182, 372],\n",
    "    [39, 350], [196, 251], [338, 273], [518, 299], [663, 315],\n",
    "    [805, 319], [920, 292], [1045, 236], [1099, 195], [1155, 154],\n",
    "    [1243, 103], [1311, 114], [1256, 176], [1205, 249], [1198, 346],\n",
    "    [1286, 433], [1454, 500], [1634, 555], [1786, 595], [1902, 621],\n",
    "    [1888, 797], [1665, 738], [1408, 684], [1184, 650], [1012, 680],\n",
    "    [856, 774], [739, 921], [659, 1047]\n",
    "], np.int32)\n",
    "\n",
    "# Main function to run video and plot real-time trajectories\n",
    "def main(args):\n",
    "    yolo_version = \"yolov8x\"\n",
    "    detector = Detector()\n",
    "    detector.load(args.cam_para, yolo_version)\n",
    "    tracker = UCMCTrack(args.a, args.a, args.wx, args.wy, args.vmax, args.cdt, args.fps, \"MOT\", args.high_score, False, None)\n",
    "    unique_car_ids = set()\n",
    "    trajectory_data = defaultdict(lambda: {'coords': [], 'class_id': None})\n",
    "    \n",
    "    cap = cv2.VideoCapture(args.video)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    \n",
    "    # Set up Matplotlib figure for trajectories\n",
    "    fig, ax = plt.subplots()\n",
    "    plt.ion()  # Interactive mode for real-time plotting\n",
    "\n",
    "    def update_trajectory_graph():\n",
    "        ax.clear()\n",
    "        ax.set_title(\"Trajectories of Tracked Vehicles\")\n",
    "        ax.set_xlabel(\"X Coordinate\")\n",
    "        ax.set_ylabel(\"Y Coordinate\")\n",
    "        for track_id, data in trajectory_data.items():\n",
    "            if data['coords']:\n",
    "                x_vals, y_vals = zip(*data['coords'])\n",
    "                class_id = data['class_id']\n",
    "                label = \"Car\" if class_id == 2 else f\"Class {class_id}\"\n",
    "                ax.plot(x_vals, y_vals, marker=\"o\", label=f'Track {track_id} ({label})')\n",
    "        ax.legend(loc=\"upper right\")\n",
    "        plt.draw()\n",
    "        plt.pause(0.001)\n",
    "\n",
    "    # Process each frame\n",
    "    frame_id = 1\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        frame = apply_green_roi_mask(frame, roi_points)\n",
    "\n",
    "        dets = detector.get_dets(frame, args.conf_thresh, [2, 5, 7])\n",
    "        tracker.update(dets, frame_id)\n",
    "\n",
    "        for det in dets:\n",
    "            if det.track_id > 0:\n",
    "                unique_car_ids.add(det.track_id)\n",
    "                trajectory_data[det.track_id]['coords'].append((det.y[0, 0], det.y[1, 0]))\n",
    "                trajectory_data[det.track_id]['class_id'] = det.det_class\n",
    "                cv2.rectangle(frame, (int(det.bb_left), int(det.bb_top)),\n",
    "                              (int(det.bb_left + det.bb_width), int(det.bb_top + det.bb_height)),\n",
    "                              (0, 255, 0), 2)\n",
    "                cv2.putText(frame, str(det.track_id), (int(det.bb_left), int(det.bb_top)),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "\n",
    "        # Display car count\n",
    "        cv2.putText(frame, f\"Cars: {len(unique_car_ids)}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "        cv2.imshow(\"Real-Time Tracking\", frame)\n",
    "        update_trajectory_graph()\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "        frame_id += 1\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    plt.close()\n",
    "\n",
    "# Argument parser setup\n",
    "parser = argparse.ArgumentParser(description='Real-time Tracking and Trajectory Plotting')\n",
    "parser.add_argument('--video', type=str, default=\"C:/research/new30s.mp4\", help='video file name')\n",
    "parser.add_argument('--cam_para', type=str, default=\"C:/research/UCMCTrack/demo/cam_para.txt\", help='camera parameter file name')\n",
    "parser.add_argument('--wx', type=float, default=5, help='wx')\n",
    "parser.add_argument('--wy', type=float, default=5, help='wy')\n",
    "parser.add_argument('--vmax', type=float, default=10, help='vmax')\n",
    "parser.add_argument('--a', type=float, default=150.0, help='assignment threshold')\n",
    "parser.add_argument('--cdt', type=float, default=15.0, help='coasted deletion time')\n",
    "parser.add_argument('--high_score', type=float, default=0.4, help='high score threshold')\n",
    "parser.add_argument('--conf_thresh', type=float, default=0.001, help='detection confidence threshold')\n",
    "parser.add_argument('--fps', type=float, default=30, help='frames per second')\n",
    "args = parser.parse_args()\n",
    "\n",
    "# Run the main function\n",
    "main(args)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# wrong shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from ultralytics import YOLO\n",
    "from tracker.ucmc import UCMCTrack\n",
    "from detector.mapper import Mapper\n",
    "from collections import defaultdict\n",
    "import argparse\n",
    "\n",
    "# Define Detection class\n",
    "class Detection:\n",
    "    def __init__(self, id, bb_left=0, bb_top=0, bb_width=0, bb_height=0, conf=0, det_class=0):\n",
    "        self.id = id\n",
    "        self.bb_left = bb_left\n",
    "        self.bb_top = bb_top\n",
    "        self.bb_width = bb_width\n",
    "        self.bb_height = bb_height\n",
    "        self.conf = conf\n",
    "        self.det_class = det_class\n",
    "        self.track_id = 0\n",
    "        self.y = np.zeros((2, 1))\n",
    "        self.R = np.eye(4)\n",
    "\n",
    "# Define Detector class\n",
    "class Detector:\n",
    "    def __init__(self):\n",
    "        self.seq_length = 0\n",
    "        self.gmc = None\n",
    "\n",
    "    def load(self, cam_para_file, yolo_version):\n",
    "        self.mapper = Mapper(cam_para_file, \"MOT17\")\n",
    "        self.model = YOLO(f'pretrained/{yolo_version}.pt')\n",
    "\n",
    "    def get_dets(self, img, conf_thresh=0, det_classes=[0]):\n",
    "        dets = []\n",
    "        frame = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        results = self.model(frame, imgsz=1088)\n",
    "        det_id = 0\n",
    "        for box in results[0].boxes:\n",
    "            conf = box.conf.cpu().numpy()[0]\n",
    "            bbox = box.xyxy.cpu().numpy()[0]\n",
    "            cls_id = box.cls.cpu().numpy()[0]\n",
    "            w = bbox[2] - bbox[0]\n",
    "            h = bbox[3] - bbox[1]\n",
    "            if w <= 10 and h <= 10 or cls_id not in det_classes or conf <= conf_thresh:\n",
    "                continue\n",
    "\n",
    "            det = Detection(det_id)\n",
    "            det.bb_left = bbox[0]\n",
    "            det.bb_top = bbox[1]\n",
    "            det.bb_width = w\n",
    "            det.bb_height = h\n",
    "            det.conf = conf\n",
    "            det.det_class = cls_id\n",
    "            det.y, det.R = self.mapper.mapto([det.bb_left, det.bb_top, det.bb_width, det.bb_height])\n",
    "            det_id += 1\n",
    "            dets.append(det)\n",
    "\n",
    "        return dets\n",
    "\n",
    "# Main function to run video and plot real-time trajectories\n",
    "def main(args):\n",
    "    yolo_version = \"yolov8x\"\n",
    "    detector = Detector()\n",
    "    detector.load(args.cam_para, yolo_version)\n",
    "    tracker = UCMCTrack(args.a, args.a, args.wx, args.wy, args.vmax, args.cdt, args.fps, \"MOT\", args.high_score, False, None)\n",
    "    unique_car_ids = set()\n",
    "    trajectory_data = defaultdict(lambda: {'coords': [], 'class_id': None})\n",
    "\n",
    "    cap = cv2.VideoCapture(args.video)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    # Initialize a white canvas as the main display\n",
    "    canvas_width = width + 400  # Additional width for the trajectory and car count\n",
    "    canvas_height = height\n",
    "    car_count_position = (width + 20, canvas_height - 30)  # Bottom-right corner of the canvas\n",
    "\n",
    "    # Set up Matplotlib figure for the trajectory plot\n",
    "    fig, ax = plt.subplots()\n",
    "    plt.ion()  # Interactive mode for real-time plotting\n",
    "\n",
    "    def update_trajectory_graph():\n",
    "        ax.clear()\n",
    "        ax.set_title(\"Trajectories of Tracked Vehicles\")\n",
    "        ax.set_xlabel(\"X Coordinate\")\n",
    "        ax.set_ylabel(\"Y Coordinate\")\n",
    "        for track_id, data in trajectory_data.items():\n",
    "            if data['coords']:\n",
    "                x_vals, y_vals = zip(*data['coords'])\n",
    "                class_id = data['class_id']\n",
    "                label = \"Car\" if class_id == 2 else f\"Class {class_id}\"\n",
    "                ax.plot(x_vals, y_vals, marker=\"o\", label=f'Track {track_id} ({label})')\n",
    "        ax.legend(loc=\"upper right\")\n",
    "        fig.canvas.draw()\n",
    "        fig_image = np.frombuffer(fig.canvas.tostring_rgb(), dtype=np.uint8)\n",
    "        fig_image = fig_image.reshape(fig.canvas.get_width_height()[::-1] + (3,))\n",
    "        return fig_image\n",
    "\n",
    "    frame_id = 1\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        dets = detector.get_dets(frame, args.conf_thresh, [2, 5, 7])\n",
    "        tracker.update(dets, frame_id)\n",
    "\n",
    "        # Update the unique car count and trajectory data\n",
    "        for det in dets:\n",
    "            if det.track_id > 0:\n",
    "                unique_car_ids.add(det.track_id)\n",
    "                trajectory_data[det.track_id]['coords'].append((det.y[0, 0], det.y[1, 0]))\n",
    "                trajectory_data[det.track_id]['class_id'] = det.det_class\n",
    "                cv2.rectangle(frame, (int(det.bb_left), int(det.bb_top)),\n",
    "                              (int(det.bb_left + det.bb_width), int(det.bb_top + det.bb_height)),\n",
    "                              (0, 255, 0), 2)\n",
    "                cv2.putText(frame, str(det.track_id), (int(det.bb_left), int(det.bb_top)),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "\n",
    "        # Create a white canvas and place the video frame on it\n",
    "        canvas = np.ones((canvas_height, canvas_width, 3), dtype=np.uint8) * 255\n",
    "        canvas[0:height, 0:width] = frame\n",
    "\n",
    "        # Get the updated trajectory plot and place it in the top-right corner\n",
    "        trajectory_img = update_trajectory_graph()\n",
    "        traj_height, traj_width, _ = trajectory_img.shape\n",
    "        canvas[10:10+traj_height, width+10:width+10+traj_width] = trajectory_img\n",
    "\n",
    "        # Display car count in the bottom-right corner\n",
    "        cv2.putText(canvas, f\"Cars: {len(unique_car_ids)}\", car_count_position, cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 0), 2)\n",
    "\n",
    "        # Display the canvas\n",
    "        cv2.imshow(\"Real-Time Tracking and Analysis\", canvas)\n",
    "\n",
    "        # Quit if 'q' is pressed\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "        frame_id += 1\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    plt.close()\n",
    "\n",
    "# Argument parser setup\n",
    "parser = argparse.ArgumentParser(description='Real-time Tracking and Trajectory Plotting')\n",
    "parser.add_argument('--video', type=str, default=\"C:/research/new30s.mp4\", help='video file name')\n",
    "parser.add_argument('--cam_para', type=str, default=\"C:/research/UCMCTrack/demo/cam_para.txt\", help='camera parameter file name')\n",
    "parser.add_argument('--wx', type=float, default=5, help='wx')\n",
    "parser.add_argument('--wy', type=float, default=5, help='wy')\n",
    "parser.add_argument('--vmax', type=float, default=10, help='vmax')\n",
    "parser.add_argument('--a', type=float, default=150.0, help='assignment threshold')\n",
    "parser.add_argument('--cdt', type=float, default=15.0, help='coasted deletion time')\n",
    "parser.add_argument('--high_score', type=float, default=0.4, help='high score threshold')\n",
    "parser.add_argument('--conf_thresh', type=float, default=0.001, help='detection confidence threshold')\n",
    "parser.add_argument('--fps', type=float, default=30, help='frames per second')\n",
    "args = parser.parse_args()\n",
    "\n",
    "# Run the main function\n",
    "main(args)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# working version\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from ultralytics import YOLO\n",
    "from tracker.ucmc import UCMCTrack\n",
    "from detector.mapper import Mapper\n",
    "from collections import defaultdict\n",
    "import argparse\n",
    "\n",
    "# Define Detection class\n",
    "class Detection:\n",
    "    def __init__(self, id, bb_left=0, bb_top=0, bb_width=0, bb_height=0, conf=0, det_class=0):\n",
    "        self.id = id\n",
    "        self.bb_left = bb_left\n",
    "        self.bb_top = bb_top\n",
    "        self.bb_width = bb_width\n",
    "        self.bb_height = bb_height\n",
    "        self.conf = conf\n",
    "        self.det_class = det_class\n",
    "        self.track_id = 0\n",
    "        self.y = np.zeros((2, 1))\n",
    "        self.R = np.eye(4)\n",
    "\n",
    "# Define Detector class\n",
    "class Detector:\n",
    "    def __init__(self):\n",
    "        self.seq_length = 0\n",
    "        self.gmc = None\n",
    "\n",
    "    def load(self, cam_para_file, yolo_version):\n",
    "        self.mapper = Mapper(cam_para_file, \"MOT17\")\n",
    "        self.model = YOLO(f'pretrained/{yolo_version}.pt')\n",
    "\n",
    "    def get_dets(self, img, conf_thresh=0, det_classes=[0]):\n",
    "        dets = []\n",
    "        frame = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        results = self.model(frame, imgsz=1088)\n",
    "        det_id = 0\n",
    "        for box in results[0].boxes:\n",
    "            conf = box.conf.cpu().numpy()[0]\n",
    "            bbox = box.xyxy.cpu().numpy()[0]\n",
    "            cls_id = box.cls.cpu().numpy()[0]\n",
    "            w = bbox[2] - bbox[0]\n",
    "            h = bbox[3] - bbox[1]\n",
    "            if w <= 10 and h <= 10 or cls_id not in det_classes or conf <= conf_thresh:\n",
    "                continue\n",
    "\n",
    "            det = Detection(det_id)\n",
    "            det.bb_left = bbox[0]\n",
    "            det.bb_top = bbox[1]\n",
    "            det.bb_width = w\n",
    "            det.bb_height = h\n",
    "            det.conf = conf\n",
    "            det.det_class = cls_id\n",
    "            det.y, det.R = self.mapper.mapto([det.bb_left, det.bb_top, det.bb_width, det.bb_height])\n",
    "            det_id += 1\n",
    "            dets.append(det)\n",
    "\n",
    "        return dets\n",
    "\n",
    "# Main function to run video and plot real-time trajectories\n",
    "def main(args):\n",
    "    yolo_version = \"yolov8x\"\n",
    "    detector = Detector()\n",
    "    detector.load(args.cam_para, yolo_version)\n",
    "    tracker = UCMCTrack(args.a, args.a, args.wx, args.wy, args.vmax, args.cdt, args.fps, \"MOT\", args.high_score, False, None)\n",
    "    unique_car_ids = set()\n",
    "    trajectory_data = defaultdict(lambda: {'coords': [], 'class_id': None})\n",
    "\n",
    "    cap = cv2.VideoCapture(args.video)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    # Define scaled down dimensions for the video frame\n",
    "    video_display_width = width // 2  # Adjust this value if needed\n",
    "    video_display_height = height // 2\n",
    "    canvas_width = video_display_width + 400  # Extra space for trajectory plot\n",
    "    canvas_height = video_display_height + 200  # Extra space for car count display\n",
    "\n",
    "    # Set up position for car count display\n",
    "    car_count_position = (video_display_width + 20, canvas_height - 30)  # Bottom-right corner\n",
    "\n",
    "    # Set up Matplotlib figure for the trajectory plot\n",
    "    fig, ax = plt.subplots()\n",
    "    plt.ion()  # Interactive mode for real-time plotting\n",
    "\n",
    "    def update_trajectory_graph():\n",
    "        ax.clear()\n",
    "        ax.set_title(\"Trajectories of Tracked Vehicles\")\n",
    "        ax.set_xlabel(\"X Coordinate\")\n",
    "        ax.set_ylabel(\"Y Coordinate\")\n",
    "        if not trajectory_data:\n",
    "            print(\"No trajectory data to display.\")\n",
    "        for track_id, data in trajectory_data.items():\n",
    "            if data['coords']:\n",
    "                x_vals, y_vals = zip(*data['coords'])\n",
    "                class_id = data['class_id']\n",
    "                label = \"Car\" if class_id == 2 else f\"Class {class_id}\"\n",
    "                ax.plot(x_vals, y_vals, marker=\"o\", label=f'Track {track_id} ({label})')\n",
    "        if trajectory_data:\n",
    "            ax.legend(loc=\"upper right\")\n",
    "        fig.canvas.draw()\n",
    "        fig_image = np.frombuffer(fig.canvas.buffer_rgba(), dtype=np.uint8)\n",
    "        fig_image = fig_image.reshape(fig.canvas.get_width_height()[::-1] + (4,))\n",
    "        fig_image = cv2.cvtColor(fig_image, cv2.COLOR_RGBA2RGB)  # Convert RGBA to RGB\n",
    "        return fig_image\n",
    "\n",
    "    frame_id = 1\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"No more frames to read.\")\n",
    "            break\n",
    "\n",
    "        # Scale down the video frame for display\n",
    "        frame_resized = cv2.resize(frame, (video_display_width, video_display_height))\n",
    "\n",
    "        dets = detector.get_dets(frame, args.conf_thresh, [2, 5, 7])\n",
    "        tracker.update(dets, frame_id)\n",
    "\n",
    "        # Update the unique car count and trajectory data\n",
    "        for det in dets:\n",
    "            if det.track_id > 0:\n",
    "                unique_car_ids.add(det.track_id)\n",
    "                trajectory_data[det.track_id]['coords'].append((det.y[0, 0], det.y[1, 0]))\n",
    "                trajectory_data[det.track_id]['class_id'] = det.det_class\n",
    "                cv2.rectangle(frame_resized, (int(det.bb_left // 2), int(det.bb_top // 2)),\n",
    "                              (int((det.bb_left + det.bb_width) // 2), int((det.bb_top + det.bb_height) // 2)),\n",
    "                              (0, 255, 0), 2)\n",
    "                cv2.putText(frame_resized, str(det.track_id), (int(det.bb_left // 2), int(det.bb_top // 2)),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1)\n",
    "\n",
    "        # Create a white canvas and place the video frame on it\n",
    "        canvas = np.ones((canvas_height, canvas_width, 3), dtype=np.uint8) * 255\n",
    "        canvas[0:video_display_height, 0:video_display_width] = frame_resized\n",
    "\n",
    "        # Get the updated trajectory plot and place it in the top-right corner\n",
    "        trajectory_img = update_trajectory_graph()\n",
    "        traj_height, traj_width, _ = trajectory_img.shape\n",
    "        resized_traj_img = cv2.resize(trajectory_img, (390, int(traj_height * (390 / traj_width))))  # Resize proportionally\n",
    "        canvas[10:10+resized_traj_img.shape[0], video_display_width+10:video_display_width+10+resized_traj_img.shape[1]] = resized_traj_img\n",
    "\n",
    "        # Display car count in the bottom-right corner\n",
    "        cv2.putText(canvas, f\"Cars: {len(unique_car_ids)}\", car_count_position, cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 0), 2)\n",
    "\n",
    "        # Display the canvas\n",
    "        cv2.imshow(\"Real-Time Tracking and Analysis\", canvas)\n",
    "\n",
    "        # Quit if 'q' is pressed\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "        frame_id += 1\n",
    "        # Debugging output\n",
    "        print(f\"Frame {frame_id}, Cars Count: {len(unique_car_ids)}, Trajectories: {len(trajectory_data)}\")\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    plt.close()\n",
    "\n",
    "# Argument parser setup\n",
    "parser = argparse.ArgumentParser(description='Real-time Tracking and Trajectory Plotting')\n",
    "parser.add_argument('--video', type=str, default=\"C:/research/new30s.mp4\", help='video file name')\n",
    "parser.add_argument('--cam_para', type=str, default=\"C:/research/UCMCTrack/demo/cam_para.txt\", help='camera parameter file name')\n",
    "parser.add_argument('--wx', type=float, default=5, help='wx')\n",
    "parser.add_argument('--wy', type=float, default=5, help='wy')\n",
    "parser.add_argument('--vmax', type=float, default=10, help='vmax')\n",
    "parser.add_argument('--a', type=float, default=150.0, help='assignment threshold')\n",
    "parser.add_argument('--cdt', type=float, default=15.0, help='coasted deletion time')\n",
    "parser.add_argument('--high_score', type=float, default=0.4, help='high score threshold')\n",
    "parser.add_argument('--conf_thresh', type=float, default=0.001, help='detection confidence threshold')\n",
    "parser.add_argument('--fps', type=float, default=30, help='frames per second')\n",
    "args = parser.parse_args()\n",
    "\n",
    "# Run the main function\n",
    "main(args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Main function to run video and plot real-time trajectories\n",
    "# def main(args):\n",
    "#     yolo_version = \"yolov8x\"\n",
    "#     detector = Detector()\n",
    "#     detector.load(args.cam_para, yolo_version)\n",
    "#     tracker = UCMCTrack(args.a, args.a, args.wx, args.wy, args.vmax, args.cdt, args.fps, \"MOT\", args.high_score, False, None)\n",
    "#     unique_car_ids = set()\n",
    "#     trajectory_data = defaultdict(lambda: {'coords': [], 'class_id': None})\n",
    "\n",
    "#     cap = cv2.VideoCapture(args.video)\n",
    "#     fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "#     width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "#     height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "#     # Define scaled down dimensions for the video frame\n",
    "#     video_display_width = width // 2  # Adjust this value if needed\n",
    "#     video_display_height = height // 2\n",
    "#     canvas_width = video_display_width + 400  # Extra space for trajectory plot\n",
    "#     canvas_height = video_display_height + 10#+ 200  # Extra space for car count display\n",
    "\n",
    "#     # Set up position for car count display\n",
    "#     car_count_position = (video_display_width + 10, canvas_height - 20)  # Bottom-right corner\n",
    "\n",
    "#     # Set up Matplotlib figure for the trajectory plot\n",
    "#     fig, ax = plt.subplots()\n",
    "#     plt.ion()  # Interactive mode for real-time plotting\n",
    "\n",
    "#     def update_trajectory_graph():\n",
    "#         ax.clear()\n",
    "#         ax.set_title(\"Trajectories of Tracked Vehicles\")\n",
    "#         ax.set_xlabel(\"X Coordinate\")\n",
    "#         ax.set_ylabel(\"Y Coordinate\")\n",
    "#         if not trajectory_data:\n",
    "#             print(\"No trajectory data to display.\")\n",
    "#         for track_id, data in trajectory_data.items():\n",
    "#             if data['coords']:\n",
    "#                 x_vals, y_vals = zip(*data['coords'])\n",
    "#                 class_id = data['class_id']\n",
    "#                 label = \"Car\" if class_id == 2 else f\"Class {class_id}\"\n",
    "#                 ax.plot(x_vals, y_vals, marker=\"o\", label=f'Track {track_id} ({label})')\n",
    "#         if trajectory_data:\n",
    "#             ax.legend(loc=\"upper right\")\n",
    "#         fig.canvas.draw()\n",
    "#         fig_image = np.frombuffer(fig.canvas.buffer_rgba(), dtype=np.uint8)\n",
    "#         fig_image = fig_image.reshape(fig.canvas.get_width_height()[::-1] + (4,))\n",
    "#         fig_image = cv2.cvtColor(fig_image, cv2.COLOR_RGBA2RGB)  # Convert RGBA to RGB\n",
    "#         return fig_image\n",
    "\n",
    "#     frame_id = 1\n",
    "#     while True:\n",
    "#         ret, frame = cap.read()\n",
    "#         if not ret:\n",
    "#             print(\"No more frames to read.\")\n",
    "#             break\n",
    "\n",
    "#         # Scale down the video frame for display\n",
    "#         frame_resized = cv2.resize(frame, (video_display_width, video_display_height))\n",
    "\n",
    "#         dets = detector.get_dets(frame, args.conf_thresh, [2, 5, 7])\n",
    "#         tracker.update(dets, frame_id)\n",
    "\n",
    "#         # Update the unique car count and trajectory data\n",
    "#         for det in dets:\n",
    "#             if det.track_id > 0:\n",
    "#                 unique_car_ids.add(det.track_id)\n",
    "#                 trajectory_data[det.track_id]['coords'].append((det.y[0, 0], det.y[1, 0]))\n",
    "#                 trajectory_data[det.track_id]['class_id'] = det.det_class\n",
    "#                 cv2.rectangle(frame_resized, (int(det.bb_left // 2), int(det.bb_top // 2)),\n",
    "#                               (int((det.bb_left + det.bb_width) // 2), int((det.bb_top + det.bb_height) // 2)),\n",
    "#                               (0, 255, 0), 2)\n",
    "#                 cv2.putText(frame_resized, str(det.track_id), (int(det.bb_left // 2), int(det.bb_top // 2)),\n",
    "#                             cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1)\n",
    "\n",
    "#         # Create a white canvas and place the video frame on it\n",
    "#         canvas = np.ones((canvas_height, canvas_width, 3), dtype=np.uint8) * 255\n",
    "#         canvas[0:video_display_height, 0:video_display_width] = frame_resized\n",
    "\n",
    "#         # Get the updated trajectory plot and place it in the top-right corner\n",
    "#         trajectory_img = update_trajectory_graph()\n",
    "#         traj_height, traj_width, _ = trajectory_img.shape\n",
    "#         resized_traj_img = cv2.resize(trajectory_img, (390, int(traj_height * (390 / traj_width))))  # Resize proportionally\n",
    "#         canvas[10:10+resized_traj_img.shape[0], video_display_width+10:video_display_width+10+resized_traj_img.shape[1]] = resized_traj_img\n",
    "\n",
    "#         # Display car count in the bottom-right corner\n",
    "#         cv2.putText(canvas, f\"Cars: {len(unique_car_ids)}\", car_count_position, cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 0), 2)\n",
    "\n",
    "#         # Display the canvas\n",
    "#         cv2.imshow(\"Real-Time Tracking and Analysis\", canvas)\n",
    "\n",
    "#         # Quit if 'q' is pressed\n",
    "#         if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "#             break\n",
    "\n",
    "#         frame_id += 1\n",
    "#         # Debugging output\n",
    "#         print(f\"Frame {frame_id}, Cars Count: {len(unique_car_ids)}, Trajectories: {len(trajectory_data)}\")\n",
    "\n",
    "#     cap.release()\n",
    "#     cv2.destroyAllWindows()\n",
    "#     plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from ultralytics import YOLO\n",
    "from tracker.ucmc import UCMCTrack\n",
    "from detector.mapper import Mapper\n",
    "from collections import defaultdict\n",
    "import argparse\n",
    "# Define the ROI points as a numpy array\n",
    "roi_points = np.array([\n",
    "    [28, 1046], [109, 977], [269, 846], [426, 715], [507, 614],\n",
    "    [570, 520], [521, 456], [427, 411], [308, 392], [182, 372],\n",
    "    [39, 350], [196, 251], [338, 273], [518, 299], [663, 315],\n",
    "    [805, 319], [920, 292], [1045, 236], [1099, 195], [1155, 154],\n",
    "    [1243, 103], [1311, 114], [1256, 176], [1205, 249], [1198, 346],\n",
    "    [1286, 433], [1454, 500], [1634, 555], [1786, 595], [1902, 621],\n",
    "    [1888, 797], [1665, 738], [1408, 684], [1184, 650], [1012, 680],\n",
    "    [856, 774], [739, 921], [659, 1047]\n",
    "], np.int32)\n",
    "\n",
    "# Define Detection class\n",
    "class Detection:\n",
    "    def __init__(self, id, bb_left=0, bb_top=0, bb_width=0, bb_height=0, conf=0, det_class=0):\n",
    "        self.id = id\n",
    "        self.bb_left = bb_left\n",
    "        self.bb_top = bb_top\n",
    "        self.bb_width = bb_width\n",
    "        self.bb_height = bb_height\n",
    "        self.conf = conf\n",
    "        self.det_class = det_class\n",
    "        self.track_id = 0\n",
    "        self.y = np.zeros((2, 1))\n",
    "        self.R = np.eye(4)\n",
    "\n",
    "# Define Detector class\n",
    "class Detector:\n",
    "    def __init__(self):\n",
    "        self.seq_length = 0\n",
    "        self.gmc = None\n",
    "\n",
    "    def load(self, cam_para_file, yolo_version):\n",
    "        self.mapper = Mapper(cam_para_file, \"MOT17\")\n",
    "        self.model = YOLO(f'pretrained/{yolo_version}.pt')\n",
    "\n",
    "    def get_dets(self, img, conf_thresh=0, det_classes=[0]):\n",
    "        dets = []\n",
    "        frame = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        results = self.model(frame, imgsz=1088)\n",
    "        det_id = 0\n",
    "        for box in results[0].boxes:\n",
    "            conf = box.conf.cpu().numpy()[0]\n",
    "            bbox = box.xyxy.cpu().numpy()[0]\n",
    "            cls_id = box.cls.cpu().numpy()[0]\n",
    "            w = bbox[2] - bbox[0]\n",
    "            h = bbox[3] - bbox[1]\n",
    "            if w <= 10 and h <= 10 or cls_id not in det_classes or conf <= conf_thresh:\n",
    "                continue\n",
    "\n",
    "            det = Detection(det_id)\n",
    "            det.bb_left = bbox[0]\n",
    "            det.bb_top = bbox[1]\n",
    "            det.bb_width = w\n",
    "            det.bb_height = h\n",
    "            det.conf = conf\n",
    "            det.det_class = cls_id\n",
    "            det.y, det.R = self.mapper.mapto([det.bb_left, det.bb_top, det.bb_width, det.bb_height])\n",
    "            det_id += 1\n",
    "            dets.append(det)\n",
    "\n",
    "        return dets\n",
    "    \n",
    "def apply_green_roi_mask(frame, points):\n",
    "    overlay = frame.copy()\n",
    "    cv2.fillPoly(overlay, [points], (0, 255, 0))  # Green color\n",
    "    alpha = 0.3  # Transparency\n",
    "    cv2.addWeighted(overlay, alpha, frame, 1 - alpha, 0, frame)\n",
    "    return frame\n",
    "\n",
    "def main(args):\n",
    "    yolo_version = \"yolov8x\"\n",
    "    detector = Detector()\n",
    "    detector.load(args.cam_para, yolo_version)\n",
    "    tracker = UCMCTrack(args.a, args.a, args.wx, args.wy, args.vmax, args.cdt, args.fps, \"MOT\", args.high_score, False, None)\n",
    "    unique_car_ids = set()\n",
    "    trajectory_data = defaultdict(lambda: {'coords': [], 'class_id': None})\n",
    "\n",
    "    cap = cv2.VideoCapture(args.video)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    # Define scaled down dimensions for the video frame\n",
    "    video_display_width = width // 2\n",
    "    video_display_height = height // 2\n",
    "    canvas_width = video_display_width + 400\n",
    "    canvas_height = video_display_height + 10\n",
    "    car_count_position = (video_display_width + 10, canvas_height - 20)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    plt.ion()\n",
    "\n",
    "    def update_trajectory_graph():\n",
    "        ax.clear()\n",
    "        ax.set_title(\"Trajectories of Tracked Vehicles\")\n",
    "        ax.set_xlabel(\"X Coordinate\")\n",
    "        ax.set_ylabel(\"Y Coordinate\")\n",
    "        for track_id, data in trajectory_data.items():\n",
    "            if data['coords']:\n",
    "                x_vals, y_vals = zip(*data['coords'])\n",
    "                ax.plot(x_vals, y_vals, marker=\"o\", label=f'Track {track_id}')\n",
    "        fig.canvas.draw()\n",
    "        fig_image = np.frombuffer(fig.canvas.buffer_rgba(), dtype=np.uint8)\n",
    "        fig_image = fig_image.reshape(fig.canvas.get_width_height()[::-1] + (4,))\n",
    "        fig_image = cv2.cvtColor(fig_image, cv2.COLOR_RGBA2RGB)\n",
    "        return fig_image\n",
    "\n",
    "    frame_id = 1\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Apply the green ROI mask to the video frame\n",
    "        frame_resized = cv2.resize(frame, (video_display_width, video_display_height))\n",
    "        frame_resized = apply_green_roi_mask(frame_resized, roi_points)\n",
    "\n",
    "        # Process detections and filter within the ROI\n",
    "        dets = detector.get_dets(frame, args.conf_thresh, [2, 5, 7])\n",
    "        tracker.update(dets, frame_id)\n",
    "\n",
    "        for det in dets:\n",
    "            # Check if detection is inside the ROI\n",
    "            center = (int(det.bb_left + det.bb_width / 2), int(det.bb_top + det.bb_height / 2))\n",
    "            if cv2.pointPolygonTest(roi_points, center, False) >= 0:\n",
    "                unique_car_ids.add(det.track_id)\n",
    "                trajectory_data[det.track_id]['coords'].append((det.y[0, 0], det.y[1, 0]))\n",
    "                cv2.rectangle(frame_resized, (int(det.bb_left // 2), int(det.bb_top // 2)),\n",
    "                              (int((det.bb_left + det.bb_width) // 2), int((det.bb_top + det.bb_height) // 2)),\n",
    "                              (0, 255, 0), 2)\n",
    "                cv2.putText(frame_resized, str(det.track_id), (int(det.bb_left // 2), int(det.bb_top // 2)),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1)\n",
    "\n",
    "        # Create the display canvas and add elements\n",
    "        canvas = np.ones((canvas_height, canvas_width, 3), dtype=np.uint8) * 255\n",
    "        canvas[0:video_display_height, 0:video_display_width] = frame_resized\n",
    "\n",
    "        # Add trajectory graph\n",
    "        trajectory_img = update_trajectory_graph()\n",
    "        traj_height, traj_width, _ = trajectory_img.shape\n",
    "        resized_traj_img = cv2.resize(trajectory_img, (390, int(traj_height * (390 / traj_width))))\n",
    "        canvas[10:10+resized_traj_img.shape[0], video_display_width+10:video_display_width+10+resized_traj_img.shape[1]] = resized_traj_img\n",
    "\n",
    "        # Display car count\n",
    "        cv2.putText(canvas, f\"Cars: {len(unique_car_ids)}\", car_count_position, cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 0), 2)\n",
    "\n",
    "        # Show the final canvas\n",
    "        cv2.imshow(\"Real-Time Tracking and Analysis\", canvas)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "        frame_id += 1\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    plt.close()\n",
    "\n",
    "# # Main function to run video and plot real-time trajectories\n",
    "# def main(args):\n",
    "#     yolo_version = \"yolov8x\"\n",
    "#     detector = Detector()\n",
    "#     detector.load(args.cam_para, yolo_version)\n",
    "#     tracker = UCMCTrack(args.a, args.a, args.wx, args.wy, args.vmax, args.cdt, args.fps, \"MOT\", args.high_score, False, None)\n",
    "#     unique_car_ids = set()\n",
    "#     trajectory_data = defaultdict(lambda: {'coords': [], 'class_id': None})\n",
    "\n",
    "#     cap = cv2.VideoCapture(args.video)\n",
    "#     fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "#     width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "#     height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "#     # Define scaled down dimensions for the video frame\n",
    "#     video_display_width = width // 2  # Adjust this value if needed\n",
    "#     video_display_height = height // 2\n",
    "#     canvas_width = video_display_width + 400  # Extra space for trajectory plot\n",
    "#     canvas_height = video_display_height + 10#+ 200  # Extra space for car count display\n",
    "\n",
    "#     # Set up position for car count display\n",
    "#     car_count_position = (video_display_width + 10, canvas_height - 20)  # Bottom-right corner\n",
    "\n",
    "#     # Set up Matplotlib figure for the trajectory plot\n",
    "#     fig, ax = plt.subplots()\n",
    "#     plt.ion()  # Interactive mode for real-time plotting\n",
    "\n",
    "#     def update_trajectory_graph():\n",
    "#         ax.clear()\n",
    "#         ax.set_title(\"Trajectories of Tracked Vehicles\")\n",
    "#         ax.set_xlabel(\"X Coordinate\")\n",
    "#         ax.set_ylabel(\"Y Coordinate\")\n",
    "#         if not trajectory_data:\n",
    "#             print(\"No trajectory data to display.\")\n",
    "#         for track_id, data in trajectory_data.items():\n",
    "#             if data['coords']:\n",
    "#                 x_vals, y_vals = zip(*data['coords'])\n",
    "#                 class_id = data['class_id']\n",
    "#                 label = \"Car\" if class_id == 2 else f\"Class {class_id}\"\n",
    "#                 ax.plot(x_vals, y_vals, marker=\"o\", label=f'Track {track_id} ({label})')\n",
    "#         if trajectory_data:\n",
    "#             ax.legend(loc=\"upper right\")\n",
    "#         fig.canvas.draw()\n",
    "#         fig_image = np.frombuffer(fig.canvas.buffer_rgba(), dtype=np.uint8)\n",
    "#         fig_image = fig_image.reshape(fig.canvas.get_width_height()[::-1] + (4,))\n",
    "#         fig_image = cv2.cvtColor(fig_image, cv2.COLOR_RGBA2RGB)  # Convert RGBA to RGB\n",
    "#         return fig_image\n",
    "\n",
    "#     frame_id = 1\n",
    "#     while True:\n",
    "#         ret, frame = cap.read()\n",
    "#         if not ret:\n",
    "#             print(\"No more frames to read.\")\n",
    "#             break\n",
    "\n",
    "#         # Scale down the video frame for display\n",
    "#         frame_resized = cv2.resize(frame, (video_display_width, video_display_height))\n",
    "\n",
    "#         dets = detector.get_dets(frame, args.conf_thresh, [2, 5, 7])\n",
    "#         tracker.update(dets, frame_id)\n",
    "\n",
    "#         # Update the unique car count and trajectory data\n",
    "#         for det in dets:\n",
    "#             if det.track_id > 0:\n",
    "#                 unique_car_ids.add(det.track_id)\n",
    "#                 trajectory_data[det.track_id]['coords'].append((det.y[0, 0], det.y[1, 0]))\n",
    "#                 trajectory_data[det.track_id]['class_id'] = det.det_class\n",
    "#                 cv2.rectangle(frame_resized, (int(det.bb_left // 2), int(det.bb_top // 2)),\n",
    "#                               (int((det.bb_left + det.bb_width) // 2), int((det.bb_top + det.bb_height) // 2)),\n",
    "#                               (0, 255, 0), 2)\n",
    "#                 cv2.putText(frame_resized, str(det.track_id), (int(det.bb_left // 2), int(det.bb_top // 2)),\n",
    "#                             cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1)\n",
    "\n",
    "#         # Create a white canvas and place the video frame on it\n",
    "#         canvas = np.ones((canvas_height, canvas_width, 3), dtype=np.uint8) * 255\n",
    "#         canvas[0:video_display_height, 0:video_display_width] = frame_resized\n",
    "\n",
    "#         # Get the updated trajectory plot and place it in the top-right corner\n",
    "#         trajectory_img = update_trajectory_graph()\n",
    "#         traj_height, traj_width, _ = trajectory_img.shape\n",
    "#         resized_traj_img = cv2.resize(trajectory_img, (390, int(traj_height * (390 / traj_width))))  # Resize proportionally\n",
    "#         canvas[10:10+resized_traj_img.shape[0], video_display_width+10:video_display_width+10+resized_traj_img.shape[1]] = resized_traj_img\n",
    "\n",
    "#         # Display car count in the bottom-right corner\n",
    "#         cv2.putText(canvas, f\"Cars: {len(unique_car_ids)}\", car_count_position, cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 0), 2)\n",
    "\n",
    "#         # Display the canvas\n",
    "#         cv2.imshow(\"Real-Time Tracking and Analysis\", canvas)\n",
    "\n",
    "#         # Quit if 'q' is pressed\n",
    "#         if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "#             break\n",
    "\n",
    "#         frame_id += 1\n",
    "#         # Debugging output\n",
    "#         print(f\"Frame {frame_id}, Cars Count: {len(unique_car_ids)}, Trajectories: {len(trajectory_data)}\")\n",
    "\n",
    "#     cap.release()\n",
    "#     cv2.destroyAllWindows()\n",
    "#     plt.close()\n",
    "\n",
    "# Argument parser setup\n",
    "parser = argparse.ArgumentParser(description='Real-time Tracking and Trajectory Plotting')\n",
    "parser.add_argument('--video', type=str, default=\"C:/research/new30s.mp4\", help='video file name')\n",
    "parser.add_argument('--cam_para', type=str, default=\"C:/research/UCMCTrack/demo/cam_para.txt\", help='camera parameter file name')\n",
    "parser.add_argument('--wx', type=float, default=5, help='wx')\n",
    "parser.add_argument('--wy', type=float, default=5, help='wy')\n",
    "parser.add_argument('--vmax', type=float, default=10, help='vmax')\n",
    "parser.add_argument('--a', type=float, default=150.0, help='assignment threshold')\n",
    "parser.add_argument('--cdt', type=float, default=15.0, help='coasted deletion time')\n",
    "parser.add_argument('--high_score', type=float, default=0.4, help='high score threshold')\n",
    "parser.add_argument('--conf_thresh', type=float, default=0.001, help='detection confidence threshold')\n",
    "parser.add_argument('--fps', type=float, default=30, help='frames per second')\n",
    "args = parser.parse_args()\n",
    "\n",
    "# Run the main function\n",
    "main(args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        # for det in dets:\n",
    "        #     center = (int(det.bb_left + det.bb_width / 2), int(det.bb_top + det.bb_height / 2))\n",
    "        #     if cv2.pointPolygonTest(roi_points, center, False) >= 0:\n",
    "        #         unique_car_ids.add(det.track_id)\n",
    "        #         trajectory_data[det.track_id]['coords'].append((det.y[0, 0], det.y[1, 0]))\n",
    "        #         class_name = class_labels.get(det.det_class, \"Unknown\")\n",
    "        #         label = f\"{class_name} {det.conf:.2f}\"\n",
    "\n",
    "        #         # Draw the bounding box, classification, and confidence score\n",
    "        #         cv2.rectangle(\n",
    "        #             frame_resized,\n",
    "        #             (int(det.bb_left // 2), int(det.bb_top // 2)),\n",
    "        #             (int((det.bb_left + det.bb_width) // 2), int((det.bb_top + det.bb_height) // 2)),\n",
    "        #             (0, 255, 0), 2\n",
    "        #         )\n",
    "        #         cv2.putText(\n",
    "        #             frame_resized, label,\n",
    "        #             (int(det.bb_left // 2), int((det.bb_top // 2) - 10)),\n",
    "        #             cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 1\n",
    "        #         )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # Main function\n",
    "# def main(args):\n",
    "#     yolo_version = \"yolo11x\"\n",
    "#     detector = Detector()\n",
    "#     detector.load(args.cam_para, yolo_version)\n",
    "#     tracker = UCMCTrack(args.a, args.a, args.wx, args.wy, args.vmax, args.cdt, args.fps, \"MOT\", args.high_score, False, None)\n",
    "#     unique_car_ids = set()\n",
    "#     trajectory_data = defaultdict(lambda: {'coords': [], 'class_id': None})\n",
    "\n",
    "#     # Define class labels\n",
    "#     class_labels = {2: \"Car\", 5: \"Bus\", 7: \"Truck\"}  # Define labels for known classes\n",
    "\n",
    "#     cap = cv2.VideoCapture(args.video)\n",
    "#     fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "#     width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "#     height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "#     video_display_width = width // 2\n",
    "#     video_display_height = height // 2\n",
    "#     canvas_width = video_display_width + 400\n",
    "#     canvas_height = video_display_height + 10\n",
    "#     car_count_position = (video_display_width + 10, canvas_height - 20)\n",
    "\n",
    "#     fig, ax = plt.subplots()\n",
    "#     plt.ion()\n",
    "\n",
    "#     def update_trajectory_graph():\n",
    "#         ax.clear()\n",
    "#         ax.set_title(\"Trajectories of Tracked Vehicles\")\n",
    "#         ax.set_xlabel(\"X Coordinate\")\n",
    "#         ax.set_ylabel(\"Y Coordinate\")\n",
    "#         for track_id, data in trajectory_data.items():\n",
    "#             if data['coords']:\n",
    "#                 x_vals, y_vals = zip(*data['coords'])\n",
    "#                 ax.plot(x_vals, y_vals, marker=\"o\", label=f'Track {track_id}')\n",
    "#         fig.canvas.draw()\n",
    "#         fig_image = np.frombuffer(fig.canvas.buffer_rgba(), dtype=np.uint8)\n",
    "#         fig_image = fig_image.reshape(fig.canvas.get_width_height()[::-1] + (4,))\n",
    "#         fig_image = cv2.cvtColor(fig_image, cv2.COLOR_RGBA2RGB)\n",
    "#         return fig_image\n",
    "\n",
    "#     frame_id = 1\n",
    "#     while True:\n",
    "#         ret, frame = cap.read()\n",
    "#         if not ret:\n",
    "#             break\n",
    "\n",
    "#         frame_resized = cv2.resize(frame, (video_display_width, video_display_height))\n",
    "#         original_size = (width, height)\n",
    "#         resized_size = (video_display_width, video_display_height)\n",
    "#         frame_resized = apply_green_roi_mask(frame_resized, roi_points, original_size, resized_size)\n",
    "\n",
    "#         dets = detector.get_dets(frame, args.conf_thresh, [2, 5, 7])\n",
    "#         tracker.update(dets, frame_id)\n",
    "\n",
    "#         for det in dets:\n",
    "#             center = (int(det.bb_left + det.bb_width / 2), int(det.bb_top + det.bb_height / 2))\n",
    "#             if cv2.pointPolygonTest(roi_points, center, False) >= 0:\n",
    "#                 unique_car_ids.add(det.track_id)\n",
    "#                 trajectory_data[det.track_id]['coords'].append((det.y[0, 0], det.y[1, 0]))\n",
    "\n",
    "#                 # Define the class name, tracking ID, and confidence score\n",
    "#                 class_name = class_labels.get(det.det_class, \"Unknown\")\n",
    "#                 label = f\"{class_name} ID:{det.track_id} {det.conf:.2f}\"\n",
    "\n",
    "#                 # Draw the bounding box, classification, confidence score, and tracking ID\n",
    "#                 cv2.rectangle(\n",
    "#                     frame_resized,\n",
    "#                     (int(det.bb_left // 2), int(det.bb_top // 2)),\n",
    "#                     (int((det.bb_left + det.bb_width) // 2), int((det.bb_top + det.bb_height) // 2)),\n",
    "#                     (0, 255, 0), 2\n",
    "#                 )\n",
    "#                 # Display the label with classification, confidence, and ID above the bounding box\n",
    "#                 cv2.putText(\n",
    "#                     frame_resized, label,\n",
    "#                     (int(det.bb_left // 2), int((det.bb_top // 2) - 10)),\n",
    "#                     cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 1\n",
    "#                 )\n",
    "\n",
    "#         canvas = np.ones((canvas_height, canvas_width, 3), dtype=np.uint8) * 255\n",
    "#         canvas[0:video_display_height, 0:video_display_width] = frame_resized\n",
    "\n",
    "#         trajectory_img = update_trajectory_graph()\n",
    "#         traj_height, traj_width, _ = trajectory_img.shape\n",
    "#         resized_traj_img = cv2.resize(trajectory_img, (390, int(traj_height * (390 / traj_width))))\n",
    "#         canvas[10:10+resized_traj_img.shape[0], video_display_width+10:video_display_width+10+resized_traj_img.shape[1]] = resized_traj_img\n",
    "\n",
    "#         cv2.putText(canvas, f\"Cars: {len(unique_car_ids)}\", car_count_position, cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 0), 2)\n",
    "#         cv2.imshow(\"Real-Time Tracking and Analysis\", canvas)\n",
    "\n",
    "#         if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "#             break\n",
    "\n",
    "#         frame_id += 1\n",
    "\n",
    "#     cap.release()\n",
    "#     cv2.destroyAllWindows()\n",
    "#     plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from ultralytics import YOLO\n",
    "from tracker.ucmc import UCMCTrack\n",
    "from detector.mapper import Mapper\n",
    "from collections import defaultdict\n",
    "import argparse\n",
    "# Define the ROI points as a numpy array\n",
    "roi_points = np.array([\n",
    "    [28, 1046], [109, 977], [269, 846], [426, 715], [507, 614],\n",
    "    [570, 520], [521, 456], [427, 411], [308, 392], [182, 372],\n",
    "    [39, 350], [196, 251], [338, 273], [518, 299], [663, 315],\n",
    "    [805, 319], [920, 292], [1045, 236], [1099, 195], [1155, 154],\n",
    "    [1243, 103], [1311, 114], [1256, 176], [1205, 249], [1198, 346],\n",
    "    [1286, 433], [1454, 500], [1634, 555], [1786, 595], [1902, 621],\n",
    "    [1888, 797], [1665, 738], [1408, 684], [1184, 650], [1012, 680],\n",
    "    [856, 774], [739, 921], [659, 1047]\n",
    "], np.int32)\n",
    "\n",
    "# Define Detection class\n",
    "class Detection:\n",
    "    def __init__(self, id, bb_left=0, bb_top=0, bb_width=0, bb_height=0, conf=0, det_class=0):\n",
    "        self.id = id\n",
    "        self.bb_left = bb_left\n",
    "        self.bb_top = bb_top\n",
    "        self.bb_width = bb_width\n",
    "        self.bb_height = bb_height\n",
    "        self.conf = conf\n",
    "        self.det_class = det_class\n",
    "        self.track_id = 0\n",
    "        self.y = np.zeros((2, 1))\n",
    "        self.R = np.eye(4)\n",
    "\n",
    "# Define Detector class\n",
    "class Detector:\n",
    "    def __init__(self):\n",
    "        self.seq_length = 0\n",
    "        self.gmc = None\n",
    "\n",
    "    def load(self, cam_para_file, yolo_version):\n",
    "        self.mapper = Mapper(cam_para_file, \"MOT17\")\n",
    "        self.model = YOLO(f'pretrained/{yolo_version}.pt')\n",
    "\n",
    "    def get_dets(self, img, conf_thresh=0, det_classes=[0]):\n",
    "        dets = []\n",
    "        frame = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        results = self.model(frame, imgsz=1088)\n",
    "        det_id = 0\n",
    "        for box in results[0].boxes:\n",
    "            conf = box.conf.cpu().numpy()[0]\n",
    "            bbox = box.xyxy.cpu().numpy()[0]\n",
    "            cls_id = box.cls.cpu().numpy()[0]\n",
    "            w = bbox[2] - bbox[0]\n",
    "            h = bbox[3] - bbox[1]\n",
    "            if w <= 10 and h <= 10 or cls_id not in det_classes or conf <= conf_thresh:\n",
    "                continue\n",
    "\n",
    "            det = Detection(det_id)\n",
    "            det.bb_left = bbox[0]\n",
    "            det.bb_top = bbox[1]\n",
    "            det.bb_width = w\n",
    "            det.bb_height = h\n",
    "            det.conf = conf\n",
    "            det.det_class = cls_id\n",
    "            det.y, det.R = self.mapper.mapto([det.bb_left, det.bb_top, det.bb_width, det.bb_height])\n",
    "            det_id += 1\n",
    "            dets.append(det)\n",
    "\n",
    "        return dets\n",
    "    \n",
    "def apply_green_roi_mask(frame, points, original_size, resized_size):\n",
    "    # Calculate the scaling factors for width and height\n",
    "    scale_x = resized_size[0] / original_size[0]\n",
    "    scale_y = resized_size[1] / original_size[1]\n",
    "\n",
    "    # Scale the ROI points according to the new size\n",
    "    scaled_points = np.array([[int(x * scale_x), int(y * scale_y)] for x, y in points], np.int32)\n",
    "\n",
    "    # Create overlay with the ROI in green\n",
    "    overlay = frame.copy()\n",
    "    cv2.fillPoly(overlay, [scaled_points], (0, 255, 0))  # Green color for ROI\n",
    "\n",
    "    # Apply transparency to the overlay\n",
    "    alpha = 0.3  # Transparency level\n",
    "    cv2.addWeighted(overlay, alpha, frame, 1 - alpha, 0, frame)\n",
    "    return frame\n",
    "\n",
    "def main(args):\n",
    "    yolo_version = \"yolov8x\"\n",
    "    detector = Detector()\n",
    "    detector.load(args.cam_para, yolo_version)\n",
    "    tracker = UCMCTrack(args.a, args.a, args.wx, args.wy, args.vmax, args.cdt, args.fps, \"MOT\", args.high_score, False, None)\n",
    "    unique_car_ids = set()\n",
    "    trajectory_data = defaultdict(lambda: {'coords': [], 'class_id': None})\n",
    "\n",
    "    cap = cv2.VideoCapture(args.video)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    # Define scaled down dimensions for the video frame\n",
    "    video_display_width = width // 2\n",
    "    video_display_height = height // 2\n",
    "    canvas_width = video_display_width + 400\n",
    "    canvas_height = video_display_height + 10\n",
    "    car_count_position = (video_display_width + 10, canvas_height - 20)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    plt.ion()\n",
    "\n",
    "    def update_trajectory_graph():\n",
    "        ax.clear()\n",
    "        ax.set_title(\"Trajectories of Tracked Vehicles\")\n",
    "        ax.set_xlabel(\"X Coordinate\")\n",
    "        ax.set_ylabel(\"Y Coordinate\")\n",
    "        for track_id, data in trajectory_data.items():\n",
    "            if data['coords']:\n",
    "                x_vals, y_vals = zip(*data['coords'])\n",
    "                ax.plot(x_vals, y_vals, marker=\"o\", label=f'Track {track_id}')\n",
    "        fig.canvas.draw()\n",
    "        fig_image = np.frombuffer(fig.canvas.buffer_rgba(), dtype=np.uint8)\n",
    "        fig_image = fig_image.reshape(fig.canvas.get_width_height()[::-1] + (4,))\n",
    "        fig_image = cv2.cvtColor(fig_image, cv2.COLOR_RGBA2RGB)\n",
    "        return fig_image\n",
    "\n",
    "    frame_id = 1\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Apply the green ROI mask to the video frame\n",
    "        frame_resized = cv2.resize(frame, (video_display_width, video_display_height))\n",
    "        # Original size of the video\n",
    "        original_size = (width, height)\n",
    "\n",
    "        # New resized dimensions for display\n",
    "        resized_size = (video_display_width, video_display_height)\n",
    "\n",
    "        # Apply the scaled ROI mask to the resized frame\n",
    "        frame_resized = apply_green_roi_mask(frame_resized, roi_points, original_size, resized_size)\n",
    "\n",
    "        # Process detections and filter within the ROI\n",
    "        dets = detector.get_dets(frame, args.conf_thresh, [2, 5, 7])\n",
    "        tracker.update(dets, frame_id)\n",
    "\n",
    "        for det in dets:\n",
    "            # Check if detection is inside the ROI\n",
    "            center = (int(det.bb_left + det.bb_width / 2), int(det.bb_top + det.bb_height / 2))\n",
    "            if cv2.pointPolygonTest(roi_points, center, False) >= 0:\n",
    "                unique_car_ids.add(det.track_id)\n",
    "                trajectory_data[det.track_id]['coords'].append((det.y[0, 0], det.y[1, 0]))\n",
    "                cv2.rectangle(frame_resized, (int(det.bb_left // 2), int(det.bb_top // 2)),\n",
    "                              (int((det.bb_left + det.bb_width) // 2), int((det.bb_top + det.bb_height) // 2)),\n",
    "                              (0, 255, 0), 2)\n",
    "                cv2.putText(frame_resized, str(det.track_id), (int(det.bb_left // 2), int(det.bb_top // 2)),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1)\n",
    "\n",
    "        # Create the display canvas and add elements\n",
    "        canvas = np.ones((canvas_height, canvas_width, 3), dtype=np.uint8) * 255\n",
    "        canvas[0:video_display_height, 0:video_display_width] = frame_resized\n",
    "\n",
    "        # Add trajectory graph\n",
    "        trajectory_img = update_trajectory_graph()\n",
    "        traj_height, traj_width, _ = trajectory_img.shape\n",
    "        resized_traj_img = cv2.resize(trajectory_img, (390, int(traj_height * (390 / traj_width))))\n",
    "        canvas[10:10+resized_traj_img.shape[0], video_display_width+10:video_display_width+10+resized_traj_img.shape[1]] = resized_traj_img\n",
    "\n",
    "        # Display car count\n",
    "        cv2.putText(canvas, f\"Cars: {len(unique_car_ids)}\", car_count_position, cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 0), 2)\n",
    "\n",
    "        # Show the final canvas\n",
    "        cv2.imshow(\"Real-Time Tracking and Analysis\", canvas)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "        frame_id += 1\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "\n",
    "# Argument parser setup\n",
    "# parser = argparse.ArgumentParser(description='Real-time Tracking and Trajectory Plotting')\n",
    "# parser.add_argument('--video', type=str, default=\"C:/research/new30s.mp4\", help='video file name')\n",
    "# parser.add_argument('--cam_para', type=str, default=\"C:/research/UCMCTrack/demo/cam_para.txt\", help='camera parameter file name')\n",
    "# parser.add_argument('--wx', type=float, default=5, help='wx')\n",
    "# parser.add_argument('--wy', type=float, default=5, help='wy')\n",
    "# parser.add_argument('--vmax', type=float, default=10, help='vmax')\n",
    "# parser.add_argument('--a', type=float, default=150.0, help='assignment threshold')\n",
    "# parser.add_argument('--cdt', type=float, default=15.0, help='coasted deletion time')\n",
    "# parser.add_argument('--high_score', type=float, default=0.4, help='high score threshold')\n",
    "# parser.add_argument('--conf_thresh', type=float, default=0.0001, help='detection confidence threshold')\n",
    "# parser.add_argument('--fps', type=float, default=30, help='frames per second')\n",
    "# args = parser.parse_args()\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Real-time Tracking and Trajectory Plotting')\n",
    "parser.add_argument('--video', type=str, default=\"C:/research/new30s.mp4\", help='video file name')\n",
    "parser.add_argument('--cam_para', type=str, default=\"C:/research/UCMCTrack/demo/cam_para.txt\", help='camera parameter file name')\n",
    "parser.add_argument('--wx', type=float, default=10, help='wx')\n",
    "parser.add_argument('--wy', type=float, default=10, help='wy')\n",
    "parser.add_argument('--vmax', type=float, default=12, help='vmax')\n",
    "parser.add_argument('--a', type=float, default=100.0, help='assignment threshold')\n",
    "parser.add_argument('--cdt', type=float, default=10.0, help='coasted deletion time')\n",
    "parser.add_argument('--high_score', type=float, default=0.001, help='high score threshold')\n",
    "parser.add_argument('--conf_thresh', type=float, default=0.5, help='detection confidence threshold')\n",
    "parser.add_argument('--fps', type=float, default=30, help='frames per second')\n",
    "args = parser.parse_args()\n",
    "\n",
    "# Run the main function\n",
    "main(args)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
